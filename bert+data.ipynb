{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKTD3eY1CWlx",
    "outputId": "11236da0-c842-4354-801b-60b80a4cbe8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: razdel in /usr/local/lib/python3.12/dist-packages (0.5.0)\n"
     ]
    }
   ],
   "source": [
    "pip install razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SD5lxWXGCWra",
    "outputId": "5bc516ad-78f6-4be0-b03b-77f64ed334ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy3 in /usr/local/lib/python3.12/dist-packages (2.0.6)\n",
      "Requirement already satisfied: dawg2-python>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from pymorphy3) (0.9.0)\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.12/dist-packages (from pymorphy3) (2.4.417150.4580142)\n",
      "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.12/dist-packages (from pymorphy3) (75.2.0)\n"
     ]
    }
   ],
   "source": [
    "pip install pymorphy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cHIzf-4MCWwM",
    "outputId": "478b25e8-9e97-4515-ee00-ae3697e4cf90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: WordCloud in /usr/local/lib/python3.12/dist-packages (1.9.4)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from WordCloud) (2.0.2)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from WordCloud) (11.3.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from WordCloud) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->WordCloud) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->WordCloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->WordCloud) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->WordCloud) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->WordCloud) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->WordCloud) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->WordCloud) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->WordCloud) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "pip install WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M59nFCKuCa0z",
    "outputId": "48e732ee-44c8-460f-ddbe-17d4a6720d57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.35.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M5Tgsv37Ca3e",
    "outputId": "7c33e588-22cb-4377-fe2e-5c57f9affc54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (0.21)\n"
     ]
    }
   ],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eo6Fn7ccDF9g"
   },
   "source": [
    "#Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EdYrC8L9Ca8R",
    "outputId": "d8c8f53d-b75c-4514-a74f-5d7ba08db72c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Используемое устройство: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from collections import Counter\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import pymorphy3\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, Trainer, TrainingArguments, AutoModelForSequenceClassification, AutoModel\n",
    "\n",
    "from datasets import Dataset as HFDataset\n",
    "\n",
    "from graphviz import Digraph\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    torch.mps.manual_seed(RANDOM_STATE)\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(RANDOM_STATE)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"✅ Используемое устройство: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxYlMIpbDJhX"
   },
   "source": [
    "#Первоначальная обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "p5kucYQdGRuD"
   },
   "outputs": [],
   "source": [
    "def prepare_data(df: pd.DataFrame, text_cols: list) -> pd.DataFrame:\n",
    "  prepared_df = df.copy()\n",
    "\n",
    "  prepared_df['skills'] = prepared_df['skills'].fillna('')\n",
    "\n",
    "  prepared_df['full_text'] = prepared_df[text_cols].agg(' | '.join, axis=1)\n",
    "\n",
    "  prepared_df['full_text'] = prepared_df['full_text'].str.replace(r'<[^>]+>', ' ', regex=True)\n",
    "  prepared_df['full_text'] = prepared_df['full_text'].str.replace(r'\\n\\n+', '\\n', regex=True)\n",
    "  prepared_df['full_text'] = prepared_df['full_text'].str.replace(r'\\t+', ' ', regex=True)\n",
    "  prepared_df['full_text'] = prepared_df['full_text'].str.replace(r' +', ' ', regex=True)\n",
    "\n",
    "  return prepared_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KxQLHg_m_crA"
   },
   "outputs": [],
   "source": [
    "full_train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IgS4IsQD_ctV",
    "outputId": "d0f2c6f2-2eff-4267-dba9-df1837611097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16667 entries, 0 to 16666\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   title            16667 non-null  object \n",
      " 1   location         16667 non-null  object \n",
      " 2   company          16667 non-null  object \n",
      " 3   skills           10842 non-null  object \n",
      " 4   description      16667 non-null  object \n",
      " 5   experience_from  16667 non-null  float64\n",
      " 6   salary_from      16667 non-null  float64\n",
      " 7   log_salary_from  16667 non-null  float64\n",
      "dtypes: float64(3), object(5)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "full_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "3t8RSM_I_cvx",
    "outputId": "396a8380-0dfc-422c-d6f1-ffe50adbd6c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skills</th>\n",
       "      <td>5825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience_from</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_from</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_salary_from</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "title                 0\n",
       "location              0\n",
       "company               0\n",
       "skills             5825\n",
       "description           0\n",
       "experience_from       0\n",
       "salary_from           0\n",
       "log_salary_from       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "Y_hUjrYu_c0-",
    "outputId": "3db6c299-8dab-454c-902e-465895358041"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skills</th>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience_from</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "title                 0\n",
       "location              0\n",
       "company               0\n",
       "skills             2014\n",
       "description           0\n",
       "experience_from       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nBwzl5W8FwRB"
   },
   "outputs": [],
   "source": [
    "full_train_df = prepare_data(full_train_df, ['title', 'location', 'company', 'skills', 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8wWv5ranHZpL"
   },
   "outputs": [],
   "source": [
    "test_df = prepare_data(test_df, ['title', 'location', 'company', 'skills', 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "p1--tKIYHZrV"
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "    full_train_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "v1Aok9OwHZto"
   },
   "outputs": [],
   "source": [
    "y_train = train_df['log_salary_from']\n",
    "y_val = val_df['log_salary_from']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Df7vO8SpPeQ4",
    "outputId": "dbe723c0-998c-4774-ccfb-a7bbb4005520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "tT5paFOUPmAl"
   },
   "outputs": [],
   "source": [
    "save_path = \"/content/drive/MyDrive/train_df.csv\"\n",
    "train_df.to_csv(save_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "jCEpXx5YRm11"
   },
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "fkS0yw1VRq4O"
   },
   "outputs": [],
   "source": [
    "val_df.to_csv(\"val_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "gBFDx5B0Rq6x"
   },
   "outputs": [],
   "source": [
    "test_df.to_csv(\"test_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2cCMS2tyPmC5"
   },
   "outputs": [],
   "source": [
    "save_path = \"/content/drive/MyDrive/val_df.csv\"\n",
    "val_df.to_csv(save_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "4f1l_o7iPmFE"
   },
   "outputs": [],
   "source": [
    "save_path = \"/content/drive/MyDrive/test_df.csv\"\n",
    "test_df.to_csv(save_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyzG-EqxKKms"
   },
   "source": [
    "# Обучение Берта+линейная часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-HVFUVPNCBl"
   },
   "outputs": [],
   "source": [
    "class BertRegressor(nn.Module):\n",
    "    def __init__(self, bert_name):\n",
    "        super(BertRegressor, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(\n",
    "            bert_name,\n",
    "            hidden_dropout_prob=0.1,\n",
    "            attention_probs_dropout_prob=0.1\n",
    "        )\n",
    "        self.regressor = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "        self.loss_fn = nn.HuberLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        logits = self.regressor(pooled_output).squeeze(-1)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "            return {\"loss\": loss, \"logits\": logits}\n",
    "        return {\"logits\": logits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89KhAodgIkpD"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'ai-forever/ruBert-base'\n",
    "tokenizer   = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gES5I08UIkuv"
   },
   "outputs": [],
   "source": [
    "model = BertRegressor(MODEL_NAME).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "susFU81aIkxJ"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3MyxcAeShU0"
   },
   "outputs": [],
   "source": [
    "train_bert_df = train_df.copy()\n",
    "val_bert_df = val_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xJCqslbnShXV"
   },
   "outputs": [],
   "source": [
    "train_bert_df = train_bert_df[['full_text', 'log_salary_from']].rename(columns={'full_text': 'text', 'log_salary_from': 'label'})\n",
    "val_bert_df = val_bert_df[['full_text', 'log_salary_from']].rename(columns={'full_text': 'text', 'log_salary_from': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JPVhfQ9HShbK"
   },
   "outputs": [],
   "source": [
    "train_hf_dataset = HFDataset.from_pandas(train_bert_df)\n",
    "val_hf_dataset = HFDataset.from_pandas(val_bert_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrf-bITyS-UA"
   },
   "outputs": [],
   "source": [
    "tokenized_train = train_hf_dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n",
    "tokenized_val = val_hf_dataset.map(tokenize_function, batched=True, remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dh2_F4yWQLID"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/Model_bert\",\n",
    "            eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=200,\n",
    "        learning_rate= 3.5e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=32,\n",
    "        save_total_limit=2,\n",
    "        num_train_epochs=4,\n",
    "        weight_decay= 0.09,\n",
    "        warmup_steps= 1500,\n",
    "        lr_scheduler_type=\"polynomial\",\n",
    "        bf16=torch.cuda.is_bf16_supported(),\n",
    "        fp16=not torch.cuda.is_bf16_supported(),\n",
    "        seed=42,\n",
    "        report_to=\"tensorboard\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"r2\",\n",
    "        greater_is_better=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEcbNVj7VuJr"
   },
   "outputs": [],
   "source": [
    "def compute_r2_score(y_true, y_pred):\n",
    "    \"\"\"Computes and prints the R2 score.\"\"\"\n",
    "    score = r2_score(y_true, y_pred)\n",
    "    print(f\"R2 Score: {score:.6f}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1R2WpHOVnrj"
   },
   "outputs": [],
   "source": [
    "def compute_metrics_for_trainer(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions.flatten()\n",
    "    labels = labels.flatten()\n",
    "    r2 = compute_r2_score(labels, predictions)\n",
    "    return {\"r2\": r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVzxPOPuQLKU"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_val,\n",
    "        compute_metrics=compute_metrics_for_trainer,\n",
    "        processing_class=tokenizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJ5TK_KnQLNE"
   },
   "outputs": [],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ET8oeDn_Qb_O"
   },
   "source": [
    "# Дообучение с последнего чекпоинта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9i-MNmRbQLZA"
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"/content/trainer_output\"\n",
    "\n",
    "import os, glob\n",
    "def get_last_ckpt(path):\n",
    "    cks = glob.glob(os.path.join(path, \"checkpoint-*\"))\n",
    "    return max(cks, key=os.path.getmtime) if cks else None\n",
    "\n",
    "last_ckpt = get_last_ckpt(OUTPUT_DIR)\n",
    "print(\"LAST CKPT:\", last_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDjq-z2ZClA5"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "new_training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=5,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=200,\n",
    "    learning_rate=3.5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    save_total_limit=2,\n",
    "    weight_decay=0.09,\n",
    "    warmup_steps=1500,\n",
    "    lr_scheduler_type=\"polynomial\",\n",
    "    bf16=torch.cuda.is_bf16_supported(),\n",
    "    fp16=not torch.cuda.is_bf16_supported(),\n",
    "    seed=42,\n",
    "    report_to=\"tensorboard\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"r2\",\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=new_training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    compute_metrics=compute_metrics_for_trainer,\n",
    "    processing_class=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train(resume_from_checkpoint=last_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyM_JmmxQgpX"
   },
   "source": [
    "# Сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "js5MXKkTClDh"
   },
   "outputs": [],
   "source": [
    "FINAL_DIR = \"/content/Model_bert_final\"\n",
    "trainer.save_model(FINAL_DIR)\n",
    "tokenizer.save_pretrained(FINAL_DIR)\n",
    "print(\"Saved to:\", FINAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53UmG60CLnnp"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "!cp -r /content/Model_bert_final /content/drive/MyDrive/trainer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPJHmgeqQwIz"
   },
   "source": [
    "# Загрузка готовой модели и eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "7mV7lMUzQlmX"
   },
   "outputs": [],
   "source": [
    "class BertRegressor(nn.Module):\n",
    "    def __init__(self, bert_name):\n",
    "        super(BertRegressor, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(\n",
    "            bert_name,\n",
    "            hidden_dropout_prob=0.1,\n",
    "            attention_probs_dropout_prob=0.1\n",
    "        )\n",
    "        self.regressor = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "        self.loss_fn = nn.HuberLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        logits = self.regressor(pooled_output).squeeze(-1)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "            return {\"loss\": loss, \"logits\": logits}\n",
    "        return {\"logits\": logits}\n",
    "\n",
    "model_dir = \"/content/drive/MyDrive/Model_bert_final\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "t31Za7-QSIGm"
   },
   "outputs": [],
   "source": [
    "from safetensors.torch import load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "mS9TfoGcQloi"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "state_dict = load_file(f\"{model_dir}/model.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YVrvXHTnQlqi",
    "outputId": "311bb5c3-67e4-46fa-dab3-670274108659"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertRegressor(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(120138, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (regressor): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (loss_fn): HuberLoss()\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertRegressor(\"ai-forever/ruBert-base\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "1BcKQmhuTZ-0"
   },
   "outputs": [],
   "source": [
    "texts_to_predict = train_df[\"full_text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jTb1lwnhQlsx",
    "outputId": "8fb46457-a689-4f28-f9b2-0951442b51b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "predictions_train = []\n",
    "for i in range(0, len(texts_to_predict), 32):\n",
    "  if i % 3000 == 0:\n",
    "    print('3000')\n",
    "  batch_texts = texts_to_predict[i:i + 32]\n",
    "  inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True,\n",
    "                           max_length=512)\n",
    "  inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "  inputs.pop(\"token_type_ids\", None)\n",
    "  with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    preds = outputs[\"logits\"].cpu().numpy().flatten()\n",
    "    predictions_train.extend(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "6lC-VDyeW3BW"
   },
   "outputs": [],
   "source": [
    "texts_to_predict = val_df[\"full_text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZ1OORs6XMoo",
    "outputId": "b1979802-5794-457b-8681-56f5d5b19fca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3334"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q2wNAIRvW3Dg",
    "outputId": "c9515fa3-80b2-4061-a1be-626f753abe26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "predictions_val = []\n",
    "for i in range(0, len(texts_to_predict), 32):\n",
    "  if i % 3000 == 0:\n",
    "    print('3000')\n",
    "  batch_texts = texts_to_predict[i:i + 32]\n",
    "  inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True,\n",
    "                           max_length=512)\n",
    "  inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "  inputs.pop(\"token_type_ids\", None)\n",
    "  with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    preds = outputs[\"logits\"].cpu().numpy().flatten()\n",
    "    predictions_val.extend(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gk7s2W0qXOTe",
    "outputId": "7e63e3e3-90e8-4dae-c96b-6bcadf89e9f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3334"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "8M9tiW9HW3Fu"
   },
   "outputs": [],
   "source": [
    "texts_to_predict = test_df[\"full_text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NsPrAgdfXQOi",
    "outputId": "7ebeef06-2eb5-44ac-d304-5e984c5a2950"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5556"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QkWhrXlcW3IM",
    "outputId": "b6ca5fec-38cb-4c53-a2df-424b7b4074bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "predictions_test = []\n",
    "for i in range(0, len(texts_to_predict), 32):\n",
    "  if i % 3000 == 0:\n",
    "    print('3000')\n",
    "  batch_texts = texts_to_predict[i:i + 32]\n",
    "  inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True,\n",
    "                           max_length=512)\n",
    "  inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "  inputs.pop(\"token_type_ids\", None)\n",
    "  with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    preds = outputs[\"logits\"].cpu().numpy().flatten()\n",
    "    predictions_test.extend(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lGv7Rn-VO5I",
    "outputId": "000d0b0f-066b-4096-d88d-255e6e03a55e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5556"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "D7-cB7hEXvtN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google.colab import files\n",
    "\n",
    "np.save(\"/content/predictions_train.npy\", np.array(predictions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "Osel-NKkXvwg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google.colab import files\n",
    "\n",
    "np.save(\"/content/predictions_val.npy\", np.array(predictions_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "aamhDV6qXvzg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google.colab import files\n",
    "\n",
    "np.save(\"/content/predictions_test.npy\", np.array(predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S6HJdXtDY3GG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "cyzG-EqxKKms",
    "ET8oeDn_Qb_O"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
